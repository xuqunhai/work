<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width">
  <title>Title</title>
  <script src="jquery-1.7.2.min.js"></script>

</head>
<body>
<div class="test"></div>
<div class="fuc">
  <button class="btn-start">开始录制 </button>
  <button class="btn-end">结束录制 </button>
</div>
<div class="output">录制过程</div>
<div class="my-audio"></div>

<script>
  $(function () {
    var c = [];
    var voice1,voice2,voice3;
    // variables
    var leftchannel = [];
    var rightchannel = [];
    var recorder = null;
    var recording = false;
    var recordingLength = 0;
    var volume = null;
    var audioInput = null;
    var sampleRate = null;
    var audioContext = null;
    var context = null;
    var outputElement = document.querySelector('.output');
    var myAudio = document.querySelector('.my-audio');
    var outputString;

    // feature detection
    if (!navigator.getUserMedia)
      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia || navigator.msGetUserMedia;

    if (navigator.getUserMedia){
      navigator.getUserMedia({audio:true}, success, function(e) {
        alert('捕获失败！');
      });
    } else alert('不支持getUserMedia');


    $('.btn-start')[0].addEventListener('click', function(e){
      recording = true;
      leftchannel.length = rightchannel.length = 0;
      recordingLength = 0;
      outputElement.innerHTML = '正在录制...';
    });

    $('.btn-end')[0].addEventListener('click', function(e){
      recording = false;

      outputElement.innerHTML = '录制完成！';

      var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
      var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
      var interleaved = interleave ( leftBuffer, rightBuffer );
      var buffer = new ArrayBuffer(44 + interleaved.length * 2);
      var buffer2 = new ArrayBuffer(interleaved.length * 2);
      var view = new DataView(buffer);
      var view2 = new DataView(buffer2);


//    把字节数据格式化成wav的格式的过程
      // RIFF chunk descriptor
      writeUTFBytes(view, 0, 'RIFF');  //资源交换文件标志RIFF
      view.setUint32(4, 44 + interleaved.length * 2, true);  //从下个地址开始到文件尾的总字节数,文件总长
      writeUTFBytes(view, 8, 'WAVE');  //WAVE文件标志,WAV就是波形音频文件(Wave Audio)
      // FMT sub-chunk
      writeUTFBytes(view, 12, 'fmt ');  //波形格式标志，最后以为是空格
      view.setUint32(16, 16, true);  //过滤字节,块长度
      view.setUint16(20, 1, true);  //PCM格式种类，1表示线性PCM编码
      // stereo (2 channels)
      view.setUint16(22, 2, true);  //通道数，2表示双声道
      view.setUint32(24, sampleRate, true);  //采样频率
      view.setUint32(28, sampleRate * 4, true);  //数据传输速率，即每秒平均字节数
      view.setUint16(32, 4, true);  //数据块对齐
      view.setUint16(34, 16, true);  //每样本bit数
      // data sub-chunk
      writeUTFBytes(view, 36, 'data');  //data文件标志
      view.setUint32(40, interleaved.length * 2, true);  //数据块总长

      // write the PCM samples
      var lng = interleaved.length;
      var index = 44;
      var volume = 1;
      for (var i = 0; i < lng; i++){
        //把原始麦克风采样完的数据，每四个字节为一段，乘以一个系数后，舍掉两个字节再保存
        view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
        index += 2;
      }

      var blob = new Blob ( [ view ], { type : 'audio/mpeg' } );
//    console.log(blob);

      // android chrome audio不支持blob
      var reader = new FileReader();
      reader.onload = function(event){
//      console.log(reader.result);
        var audio = window.document.createElement('audio');
        console.log(event.target.result);
        c.push(event.target.result);
        audio.src = event.target.result;
        audio.controls = true;
        myAudio.appendChild(audio);
      };
      // 转换base64
      reader.readAsDataURL(blob);

    });

//  双声道的文件，采样数据按时间先后顺序交叉地存入。
    function interleave(leftChannel, rightChannel){
      var length = leftChannel.length + rightChannel.length;
      var result = new Float32Array(length);

      var inputIndex = 0;

      for (var index = 0; index < length; ){
        result[index++] = leftChannel[inputIndex];
        result[index++] = rightChannel[inputIndex];
        inputIndex++;
      }
      return result;
    }

    function mergeBuffers(channelBuffer, recordingLength){
      var result = new Float32Array(recordingLength);
      var offset = 0;
      var lng = channelBuffer.length;
      for (var i = 0; i < lng; i++){
        var buffer = channelBuffer[i];
        result.set(buffer, offset);
        offset += buffer.length;
      }
      return result;
    }

    function writeUTFBytes(view, offset, string){
      var lng = string.length;
      for (var i = 0; i < lng; i++){
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    function success(e){
//    console.log('successFunctionEvent: '+window.URL.createObjectURL(e));
      // creates the audio context
      audioContext = window.AudioContext || window.webkitAudioContext;
      context = new audioContext();

      // we query the context sample rate (varies depending on platforms)
      sampleRate = context.sampleRate;

//    console.log('context.sampleRate: '+context.sampleRate);

      // creates a gain node
      volume = context.createGain();
//    console.log(volume);

      // creates an audio node from the microphone incoming stream
      audioInput = context.createMediaStreamSource(e);

      // connect the stream to the gain node
      audioInput.connect(volume);

      /* From the spec: This value controls how frequently the audioprocess event is
       dispatched and how many sample-frames need to be processed each call.
       Lower values for buffer size will result in a lower (better) latency.
       Higher values will be necessary to avoid audio breakup and glitches */
      var bufferSize = 2048;
      recorder = context.createScriptProcessor(bufferSize, 2, 2);

      recorder.onaudioprocess = function(e){
        console.log('onaudioprocess');
        if (!recording) return;
        var left = e.inputBuffer.getChannelData (0);
        var right = e.inputBuffer.getChannelData (1);
//      console.log('left: '+left);
        // we clone the samples
        leftchannel.push (new Float32Array (left));
        rightchannel.push (new Float32Array (right));
        recordingLength += bufferSize;
      };

      // we connect the recorder
      volume.connect (recorder);
      recorder.connect (context.destination);
    }

    var regJson = {"speechText":"6","type":"register","appId":"10007","scene":"dmz_cll","serialNumber":"GOOD00001000420170425339876","userId":"u902","voice1":c[0],"voice2":c[0],"voice3":c[0]};
      $.ajax({
        url: 'http://vprc-core.pingan.com.cn/vprc_core_portal/rest/api/register_new',
        type: 'POST',
        data: regJson,
        dataType : 'json',
        success: function (data) {
          console.log('suc');
          console.log(data);
        },
        error: function (err) {
          console.log('err');
          console.log(err);
        }
      });

    var timer = setInterval(function () {
      if(c.length == 3){
        clearInterval(timer);
        var regJson = {"speechText":"12","type":"register","appId":"1007","scene":"dmz_cll","serialNumber":"GOOD00001000420170425339876","userId":"u902","voice1":c[0],"voice2":c[1],"voice3":c[2]};
        var regAjax = function () {
          console.log(666);
          $.ajax({
            url: 'https://test-vprc-core.pingan.com.cn:56433/vprc_core_portal/rest/api/register_new',
            type: 'POST',
            data: regJson,
            dataType : 'json',
            success: function (data) {
              console.log('suc');
              console.log(data);
            },
            error: function (err) {
              console.log('err');
              console.log(err);
            }
          });
        };
        regAjax();
      }
    },1000);

});


/*
  var speechText = {"appId":"10007","scene":"dmz_cll","userId":"test-test-test","type":"1"};
  $.ajax({
    url: 'http://vprc-core.pingan.com.cn/vprc_core_portal/rest/api/getSpeechText',
    type: 'POST',
    data: speechText,
    dataType : 'json',
    success: function (data) {
      console.log('suc');
      console.log(data);
    },
    error: function (err) {
      console.log('err');
      console.log(err);
    }
  });
*/

</script>
</body>
</html>