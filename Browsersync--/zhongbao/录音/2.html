<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>捕捉用户麦克风getUserMedia</title>
  <style>
    body,dl,dd,ul,li,p{margin: 0;padding: 0;font-size: 12px;line-height: 22px;font-family: arial}
    body{width: 100%;overflow-x: hidden;}
    h2,h3{margin: 0;padding: 0;}
    h1{text-align: center;}
    h2{margin-top: 10px;}
    table{width: 100%;}
    table td, table th{padding: 3px;}
    table th{background-color: #cee;}
    dl{margin-top: 10px;}
    dl{padding: 3px;}
    dt{font-weight: bold;}
    dl dt{padding: 5px;background-color: #cee;}
    video{display: block;height: 100px;margin: 10px auto;}
    .fuc{padding: 10px;background-color: #eee;overflow: hidden;}
    .fuc button{float: left;padding: 10px;}
    .fuc .btn-end{float: right;}
    .output{padding: 10px;text-align: center;}




  </style>
  <!-- 设计：brucewan | 重构：brucewan | 创建：2015-05-12 10:04:45 | 更新：| 团队博客：http://tgideas.qq.com/ -->
</head>
<body>
<h1>捕捉用户麦克风getUserMedia</h1>
<div class="fuc">
  <button class="btn-start">开始录制 </button>
  <button class="btn-end">结束录制 </button>
</div>
<p class="output">点击“开始录制”按钮开始录音</p>
<div class="my-audio"></div>
<h2>测试结果：</h2>
<table>
  <tr><th>系统支持：</th><td>android chrome，且有数据丢失</td></tr>
  <tr><th>其它问题：</th><td>android audio不支持blob</td></tr>
</table>
<script>

  // lib
  var $ = function(className){return document.querySelector(className)};

  // variables
  var leftchannel = [];
  var rightchannel = [];
  var recorder = null;
  var recording = false;
  var recordingLength = 0;
  var volume = null;
  var audioInput = null;
  var sampleRate = null;
  var audioContext = null;
  var context = null;
  var outputElement = document.querySelector('.output');
  var myAudio = document.querySelector('.my-audio');
  var outputString;

  // feature detection
  if (!navigator.getUserMedia)
    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
      navigator.mozGetUserMedia || navigator.msGetUserMedia;

  if (navigator.getUserMedia){
    navigator.getUserMedia({audio:true}, success, function(e) {
      // alert('捕获失败！');
    });
  } else alert('不支持getUserMedia');


  // if R is pressed, we start recording

  $('.btn-start').addEventListener('click', function(e){
    recording = true;
    // reset the buffers for the new recording
    leftchannel.length = rightchannel.length = 0;
    recordingLength = 0;
    outputElement.innerHTML = '正在录制...';
  });

  $('.btn-end').addEventListener('click', function(e){
    // we stop recording
    recording = false;

    outputElement.innerHTML = '录制完成！';

    // we flat the left and right channels down
    var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
    var rightBuffer = mergeBuffers ( rightchannel, recordingLength );
    // we interleave both channels together
    var interleaved = interleave ( leftBuffer, rightBuffer );

    // we create our wav file
    var buffer = new ArrayBuffer(44 + interleaved.length * 2);


    var view = new DataView(buffer);

    // RIFF chunk descriptor
    writeUTFBytes(view, 0, 'RIFF');
    view.setUint32(4, 44 + interleaved.length * 2, true);
    writeUTFBytes(view, 8, 'WAVE');
    // FMT sub-chunk
    writeUTFBytes(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    // stereo (2 channels)
    view.setUint16(22, 2, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 4, true);
    view.setUint16(32, 4, true);
    view.setUint16(34, 16, true);
    // data sub-chunk
    writeUTFBytes(view, 36, 'data');
    view.setUint32(40, interleaved.length * 2, true);

    // write the PCM samples
    var lng = interleaved.length;
    var index = 44;
    var volume = 1;
    for (var i = 0; i < lng; i++){
      view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
      index += 2;
    }

    var blob = new Blob ( [ view ], { type : 'audio/mpeg' } );

    // android chrome audio不支持blob
    var reader = new FileReader();
    reader.onload = function(event){
      var audio = window.document.createElement('audio');
      audio.src = event.target.result;
      audio.controls = true;
      myAudio.appendChild(audio);
    };
    // 转换base64
    reader.readAsDataURL(blob);

  });

//将左右声道数据交叉存入Float32Array数组并返回
  function interleave(leftChannel, rightChannel){
    var length = leftChannel.length + rightChannel.length;
    var result = new Float32Array(length);

    var inputIndex = 0;

    for (var index = 0; index < length; ){
      result[index++] = leftChannel[inputIndex];
      result[index++] = rightChannel[inputIndex];
      inputIndex++;
    }
    return result;
  }
//将channelBuffer里数据存入Float32Array数组并返回数组
  function mergeBuffers(channelBuffer, recordingLength){
    var result = new Float32Array(recordingLength);
    var offset = 0;
    var lng = channelBuffer.length;
    for (var i = 0; i < lng; i++){
      var buffer = channelBuffer[i];
      result.set(buffer, offset);
      offset += buffer.length;
    }
    return result;
  }

  function writeUTFBytes(view, offset, string){
    var lng = string.length;
    for (var i = 0; i < lng; i++){
//      在相对于视图开始处的指定字节偏移量位置处存储 Uint8 值。
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }

  function success(e){
    // creates the audio context
    audioContext = window.AudioContext || window.webkitAudioContext;
    context = new audioContext();

    // we query the context sample rate (varies depending on platforms)
    sampleRate = context.sampleRate;

    console.log('succcess');

    // creates a gain node
    volume = context.createGain();

    // creates an audio node from the microphone incoming stream
    audioInput = context.createMediaStreamSource(e);

    // connect the stream to the gain node
    audioInput.connect(volume);

    /* From the spec: This value controls how frequently the audioprocess event is
     dispatched and how many sample-frames need to be processed each call.
     Lower values for buffer size will result in a lower (better) latency.
     Higher values will be necessary to avoid audio breakup and glitches */
    var bufferSize = 2048;
    recorder = context.createScriptProcessor(bufferSize, 2, 2);

    recorder.onaudioprocess = function(e){
      if (!recording) return;
      var left = e.inputBuffer.getChannelData (0);
      var right = e.inputBuffer.getChannelData (1);
      // we clone the samples
      leftchannel.push (new Float32Array (left));
      rightchannel.push (new Float32Array (right));
      recordingLength += bufferSize;
      console.log('recording');
    }

    // we connect the recorder
    volume.connect (recorder);
    recorder.connect (context.destination);
  }

</script>
</body>
</html>